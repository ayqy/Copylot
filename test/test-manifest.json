[
  {
    "path": "cases/1.html",
    "title": "1",
    "expected": "[<--](aiguide1.html)**Page 2/3** • [\\-->](aiguide3.html)\n\n[Visit wuu73.org](https://wuu73.org)\n\nLast updated: July 2025\n\n## Model Strategy: Picking the Right Brain for the Job\n\nSince many great models are free to use via web interfaces (like Gemini in [AI Studio](https://aistudio.google.com/), [Grok](https://grok.com/), [Deepseek](https://chat.deepseek.com/)), I prioritize these. [Poe.com](https://poe.com/) also gives free daily credits for top models like Claude and the new o4 series.\n\n**Gemini 2.5 Pro** (via [AI Studio](https://aistudio.google.com/)) is great for debugging, great for planning, and also finding it the best at lots of things now. For really thorny issues, I might try the new **o4-mini** (available via [OpenRouter](https://openrouter.ai/) or [Poe](https://poe.com/)). It surprisingly fixed a persistent bug for me right away, though I'm still figuring out its best use cases. It's notably cheaper via API than the previous top dogs like Claude 3.5/3.7/4.\n\nI usually try **Claude 3.7 or 4** at some point, via [Poe](https://poe.com/) or API ([OpenRouter](https://openrouter.ai/) makes this easy), or github Copilot chat (you can get some free usage from that if you don't pay) but it's pricier for frequent use. Think of Claude 3.7 and 4 as Claude on Adderall – brilliant, sometimes verbose, maybe a bit 'psychotic' like Hunter S. Thompson. Lots of great output, but you might need a calmer model like **Claude 3.5** to refine it or do the actual coding.\n\n**Gemini 2.5 Pro** (via [AI Studio](https://aistudio.google.com/)) is great for debugging, great for planning, and also finding it the best at lots of things now. The new **Gemini 2.5 Pro** model shows even better performance across coding tasks. For really thorny issues, I might try the new **o4-mini** (available via [OpenRouter](https://openrouter.ai/) or [Poe](https://poe.com/)). It surprisingly fixed a persistent bug for me right away, though I'm still figuring out its best use cases. It's notably cheaper via API than the previous top dogs like Claude 3.5/3.7.\n\nFor really hard problems, try using OpenAI's o3 or GLM 4.5, Qwen3 Coder 480b. You can get lots of free daily tokens if you set your account to allow sharing of your data to help train models. Go to the Open AI Playground page, click the settings icon in the upper right, then click Data Controls on the left sidebar, then Sharing on the displayed page, there you can change the \"Share inputs and outputs with OpenAI\" setting to Enabled, which will give you:\n\n-   Up to 250 thousand tokens per day across gpt-5, gpt-4.1, gpt-4o, o1 and o3\n-   Up to 2.5 million tokens per day across gpt-4.1-mini, gpt-4.1-nano, gpt-4o-mini, o1-mini, o3-mini, o4-mini, and codex-mini-latest\n\nThis is really awesome, o3 and GPT 4.5 seem super genius! Sometimes in the OpenAI Playground, I have it set up to use o3 and o4-mini side-by-side, to compare them. This helps me get a feel for which ones are best for which types of problems.\n\n**Claude 4 and 3.7** is always a good option to try and fix hard problems quickly, it is just harder to access it for cheap or free. But it is often the best out of them all. When you really need to fix something fast, use it. [Poe](https://poe.com/) has free tokens for all models, daily. [OpenRouter](https://openrouter.ai/) has all models paid and/or free. Claude 3.7 is Claude on caffeine – brilliant, sometimes verbose, maybe a bit 'psychotic' like Hunter S. Thompson. Lots of great output, but you might need a calmer model like **Claude 3.5 / 4** to refine it or do the actual coding.\n\n## The Hybrid Approach: Premium Planning + Budget Execution\n\nAfter extensive testing with various models, I've developed a hybrid strategy that maximizes both quality and cost-effectiveness. The key insight is that different models excel at different parts of the development process.\n\n## My \"smart juice\" theory of model intelligence - How Models become stupid under certain circumstances\n\nAI models are usually smarter the less text you send to them. Think of each model as having a fixed amount of \"intelligence\" or \"smart juice\" available for every question or problem you ask. When you send a simple, focused prompt, nearly 100% of that intelligence is available to solve your problem. But the more complex your input—long agentic instructions about how to use tools, lots of context unrelated to your specific problem, or multiple pages of code—the more of that \"smart juice\" gets used up just processing the unrelated stuff like how it can use tools in your IDE, leaving less intelligence energy available for your actual problem.\n\nThis is why tools like Cursor, Cline, and other agentic systems can sometimes seem less effective: if they send five giant pages of instructions and context before even getting to your real question, the model's available intelligence for your specific problem drops. The more \"stuff\" you send, the more diluted the model's focus becomes. For best results, keep your prompts as concise and targeted as possible—curate the context so the model can use its full intelligence on what matters most.\n\nWhen you have a hard problem or bug, you will usually save time by using AI Code Prep to dump it into a web chat (as discussed on page 1 of this guide). It cuts out all the extra instructions and stuff that get sent in agentic IDEs/apps. I noticed that this works better even if you give the AI ALL of the files from your project. The agentic instructions/stuff/bloat that is unrelated to your actual problem is the content that seems to make the AI dumber/run out of juice.\n\n**My Workflow is something like this when starting a new project:**\n\n1.  **Plan & Brainstorm:** Use the smarter/free web models (Gemini 2.5, o4-mini, Claude 3.7, 4, o3, etc) to figure out the approach, plan the steps, identify libraries, etc.\n2.  **Generate Agent Prompt:** Ask one of these smart models: \"Write a detailed-enough prompt for [Cline](https://cline.bot/), my AI coding agent, to complete the following tasks: \\[describe tasks\\]\". Sometimes, I'll copy this generated prompt and paste it into *another* free AI good at rewriting (like [ChatGPT](https://chatgpt.com/)) to refine it further.\n3.  **Execute with Cline:** Paste the step-by-step task list into [Cline](https://cline.bot/), configured to use a stable and efficient model like **GPT 4.1 or Claude 3.5** (or Claude 4 if it is doing really complicated things). The 4.1's have been trained to follow instructions well.\n4.  **Fallback:** If GPT 4.1 struggles, switch [Cline](https://cline.bot/) to use **Claude 3.5** via API. It seems to be the next best for reliable execution. [Deepseek v3 or R1](https://chat.deepseek.com/) is really great at following instructions as well.\n\nEssentially: Use expensive/smart models (and the excellent free Gemini 2.5 Pro) to strategize and plan. Validate the plan by pasting it into 2-3 other free models ([Deepseek R1](https://chat.deepseek.com/), Claude on [Poe](https://poe.com/) if context allows) and ask \"Is this good? Can you improve it or find flaws?\". Then, use a stable workhorse like GPT 4.1 or Claude 3.5 within [Cline](https://cline.bot/) to do the heavy lifting (coding).\n\n**o4-mini** seems particularly adept at untangling complex code logic or figuring out high-level implementation strategies (like choosing frameworks or libraries). I'll often throw my initial idea at Gemini 2.5, o4-mini, GPT 4.1, [ChatGPT](https://chatgpt.com/), maybe o3-mini (try [duck.ai](https://duckduckgo.com/chat) - often free), and [Phind](https://phind.com) to get a range of ideas. If the free/cheap options don't crack it, I'll escalate to pricier models via API.\n\n## Alternative Agents & Setups\n\n[Trae.ai](https://trae.ai/) (from Bytedance, makers of TikTok) is a free VS Code compatible IDE with free AI usage, including Claude 4, Claude 3.7, Claude 3.5, and GPT 4.1. Their agents aren't as good as Cline (nothing is as good, to be honest!) but it's free and gives access to the best models. Sometimes, I find its built-in agent isn't as robust as [Cline](https://cline.bot/). However, since [Trae](https://trae.ai/) seems to be a VS Code clone, you can likely install the [Cline](https://cline.bot/) extension within it! However... it is too overloaded to get any free usage from it, its too slow. I'll still mention it though.. but meh.\n\nSo, you could have two setups:\n\n-   VS Code + [Cline](https://cline.bot/) extension + [Copilot](https://github.com/features/copilot) extension (get the $10/mo subscription for cheap API access via Cline, though the free tier might offer some basic use).\n-   [Trae.ai](https://trae.ai/) + [Cline](https://cline.bot/) extension (potentially leveraging Trae's free model access if Cline can use it, or using your own API keys).\n\nTry both! Sometimes the native [Copilot](https://github.com/features/copilot) agent solves things [Cline](https://cline.bot/) struggles with, and vice-versa. I suspect [Cline](https://cline.bot/) sometimes sends overly large prompts which might hinder performance on certain tasks compared to the more integrated Copilot agent.\n\n### Roo Code: Cline's Clone\n\n#### Roo Code\n\nRoo Code is a clone of Cline, very similar but with some different features that are worth trying out. Sometimes Cline might work better for your workflow, and sometimes Roo Code will. It's a good idea to try both and see which fits your needs for a given project or coding style.\n\n[Cline](https://cline.bot/) for VS Code is free, but remember you pay for the API calls unless you're leveraging the [Copilot](https://github.com/features/copilot) subscription trick. Using the VS Code LM API setting in [Cline](https://cline.bot/) with a $10/month Copilot sub is currently the most cost-effective way to get near-unlimited access to powerful models within the agent.\n\n#### New CLI Tools: Claude Code, Qwen Code, Gemini CLI\n\nThere’s a lot of buzz about new CLI tools for coding, especially **Claude Code**, **Qwen Code**, and **Gemini CLI**. People rave about Claude Code’s capabilities, though I haven’t tried it myself yet. When I do, I plan to set it up to use **GLM 4.5** instead (there’s a guide for this on the z.ai website).\n\nClaude Code supports subagents—these are agents that only do one task and don’t use extra tools. This setup can mimic the streamlined workflow described in this guide, focusing the model’s intelligence on a single job. Subagents are a clever way to avoid the “bloat” of agentic instructions and keep things efficient.\n\nIf you want to experiment, check out the guides and community tips for configuring these tools. The ecosystem is evolving quickly, and each tool has its own strengths for different workflows.\n\n[<--](aiguide1.html)[\\-->](aiguide3.html)"
  },
  {
    "path": "cases/2.html",
    "title": "2",
    "expected": "![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/ljT2Dmxwr8xNibumfwdLX63Y8PYB5z20xg4GwN9zZ70G4IooRSOrk9vapa0vYnpYHicISEfic6eflLThAfF0VlL9Q/0?wx_fmt=jpeg)\n\n# AI Agent的终极未来｜3万字圆桌实录\n\nOriginal 仲夏六日谈 腾讯研究院;)\n\n*2025年07月30日 17:01*\n\n![Image](https://mmbiz.qpic.cn/mmbiz_jpg/ljT2Dmxwr8xNibumfwdLX63Y8PYB5z20xTo7XITCtHUTTCmOIwKZE0dUrZ8NreRkwESZa3ayAmWvvRJAanV1VzQ/640?wx_fmt=jpeg&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)\n\n本期为《仲夏六日谈》第四季第三期节目文字内容，主题为**《执行力跃迁，AI智能体的远与近》。**\n\n**十大看点：**\n\n·何为智能体，用户真正需要的智能体是什么？\n\n·智能体是未来AI原生应用的主形态？\n\n·基模进化是否会挤压垂类Agent产品的生存空间？\n\n·主流Agent产品形态的差异在何，如何判断Agent的通用性？\n\n·智能体产品落地过程中面临的核心难题？\n\n·好坏之分，如何建立智能体的有效评估机制？\n\n·物理与数字，具身智能是智能体吗？\n\n·MCP必将是未来智能体的底层基础协议？\n\n·C端与B端商业化路径异同，Agent as a service成为新商业模式？\n\n·未来Agent爆发将出现在哪？关键因素是什么？\n\n**对话嘉宾：**\n\n****张俊九 实在智能联合创始人****\n\n****廉和 ami.ai联合创始人兼CEO****\n\n**揭光发**腾讯专家工程师\n\n刘琼（主持）腾讯研究院副院长\n\n**执行力跃迁，AI智能体的远与近**\n\n刘琼：各位嘉宾朋友们，大家好，欢迎来到腾讯研究院《仲夏六日谈》智能体圆桌研讨的专场。我是今天的主持人刘琼。昨天在飞机上准备主持稿的时候，我认真地想了一下——如果我有一个智能体，能帮我完成这些任务就好了。比如自动整理嘉宾信息、实时生成追问，还能润色我的稿子。然而，目前市面上的智能体产品，还远未达到这样的能力水平。这也是我们今天希望深入探讨的话题之一。我们想了解：什么才是一款真正被用户需要的智能体？它应呈现出怎样的形态？距离我们心目中的理想状态还有多远？在落地过程中又面临哪些“卡点”？\n\n为了深入探讨这些问题，我们非常荣幸邀请到三位来自智能体一线实践的嘉宾，他们的组合也具有很强的代表性。首先是我左手边的张俊九，张总，他是实在智能的联合创始人，也是To B (面向企业)智能体的实战派；中间这位是腾讯专家工程师揭光发老师，他自我定位为“Agent布道师”；最右边是ami.ai的联合创始人兼CEO廉和，廉总，他正专注于C端AI的创业。\n\n我们今天的开场问题是一个看似简单却争论不休的问题——“什么是Agent（智能体）”？三位嘉宾也可以先简要介绍一下目前所从事的工作，并结合自身经验，谈谈你们如何定义智能体，以及它与传统软件自动化工具的核心区别在哪里。我们先请九哥开始。\n\n张俊九：好的，谢谢刘老师。我是实在智能的联合创始人、CMO(首席营销官,Chief Marketing Officer)。自2018年起，我们便专注在人机协同这个赛道，尤其关注办公场景中，人和机器如何更好地协同工作。在我们的设想中，智能体更像是一个“助手”，能够替代或辅助人完成某些特定任务。前两年的产品中，我们的核心技术基座是AI+RPA(机器人流程自动化, Robotic Process Automation)。而从2022年大模型兴起开始，2023年我们也切入了智能体赛道。在我看来，智能体的定义是较为传统且清晰的——它是一个集合了记忆(memory)、规划(planning)、执行(execution)和总结(reflection)能力的系统，模拟人类完成某项任务。\n\n基于这个定义，我们在RPA的基础上进行了升级，它可以将日常工作流程中的SOP(标准作业程序, Standard Operating Procedure)转化为可控的、节点化的工作流，以端到端的方式呈现。我们的聚焦点依旧在B端场景，目标是帮助或替代人类完成重复性强的工作。这类智能体通常具备四个方面的能力：感知环境、规划步骤、执行动作（通过API \\[应用程序编程接口, Application Programming Interface\\] 或RPA），以及调用工具完成闭环。所以从定义角度来看，它确实是一种智能体的形态。不过我们也观察到，智能体的形态正在不断丰富。不论是在模型层面，还是MCP(智能体元协议,Meta-protocol for an Agent-based Computer)生态构建层面，这一趋势都在发展。\n\n总结来说，用一句话定义：智能体就是能够帮助人完成任务的、以大模型为驱动基础的系统。至于各种工具，我认为都可以被纳入到这个生态中来。稍后我们可以展开进一步探讨。\n\n刘琼：好的，廉总您怎么看？\n\n廉和：我目前从事的是C端方向的创业，我们公司的名字叫AMI，在法语中是“朋友”的意思。最初，我并没有严格地将我们的产品定义为“Agent”。但我认为，“Agent”这个词的含义就是作为“代理人”去完成某些任务——它始终是围绕“人”来展开的。因此，我们公司的理念是打造一个AI，它可以和用户很好地协同。“朋友”这一概念，代表了AI应当成为人的伙伴。从这个角度看，Agent的不同层级，其实体现在它与人配合的深度上。最终目标是：AI能够真正理解用户的意图，并在此基础上替代用户完成任务。\n\n目前我们的产品形态还处于初期，主要是为小朋友提供英语学习环境。未来我们当然希望它可以胜任更多任务。今天有很多技术专家在场，也希望就技术实现层面和C端商业实践中对Agent的不同理解，展开更多交流。\n\n刘琼：张总的关键词是“任务”？\n\n张俊九：对。\n\n刘琼：廉总的关键词是“陪伴”。那揭老师，您的关键词是什么？\n\n揭光发：我还是先做个简要介绍吧。我在腾讯从2023年就开始做一些智能体相关的实践。最初，其实并没有一个非常明确的Agent定义。但现在回头看，其实可以引用OpenAI研究员——一位华人学者翁先生提出的定义：所谓智能体，是指基于大模型，具备记忆、具备规划能力、并能使用工具的智能程序。满足这三个特征的程序，我们可以称之为“智能体”。这个定义得到了很多人的共识，刚刚九哥其实也提到“感知”这一点，我个人认为感知是智能体中非常关键的一个特征。从技术角度讲，感知能力可以部分地被纳入到记忆机制中——包括对话上下文的处理等。\n\n所以，从这个定义出发，我们就可以来判断哪些是智能体，哪些不是。例如，静态的工作流（workflow），或者一次性往返的对话流程，如果不具备工具调用或自主规划能力，那它可能就不能被称为“智能体”。不过，最近吴恩达老师在一次访谈中说：“我们不必纠结智能体的定义”。我今天来也想传达他的这句话。他提出一个新概念叫“agentic system”，即不论一个系统的智能程度如何，只要具备Agent的一些属性，就可以视为智能程序。他认为关键是度量其“Agent程度”即可，就像自动驾驶一样，我们可以将智能程度分级，从L0到L5。事实上，国内也有一些学者提出类似分级思路。所以现在我们认为：不管自主性强弱，只要具备一定智能行为的系统，都可以被纳入智能体或智能程序的范畴。原来我们认为只有强自主性才算“智能体”，现在可以更宽泛地理解为“智能系统”的一个谱系。\n\n刘琼：技术本身就是一个渐进演进的过程。\n\n揭光发：没错。\n\n刘琼：那三位嘉宾认为，智能体会是未来AI原生应用的主要形态之一吗？\n\n揭光发：其实早在去年我们就讨论过这个话题，当时比较主流的声音之一就是，智能体（Agent）是大模型落地的必经之路。这一波AI浪潮其实是从ChatGPT开始兴起的。\n\n刘琼：对。\n\n揭光发：由此带出的问题就是，如果只停留在“说”而不“做”就无法真正落地，因此必须寻找一种能够连接物理世界的路径来实现。这个路径可能包括多模态大模型的支持、视觉能力、动作执行能力、API调用，甚至现在的具身智能。这些技术方式本质上都是与物理世界的连接，因此可以被统称为“智能体”。从这个意义上说，智能体的概念应被视为大模型落地的一种必然路径，这一点我认为是毋庸置疑的。我的理解是：我们可以把所有基于大模型、并能与物理世界建立连接的系统，统称为一个“智能体生态”。这是我对于智能体与大模型之间关系的定位方式。\n\n廉和：我觉得从一个更朴素的视角来看，智能体的本质是“完成任务”。它的核心目标就是“把事干成”。过去我们完成一件事，可以依靠软件，也可以雇人来做；而未来，智能体将成为一种全新的实现形态。它的目标还是“把事情做了”，但交互方式发生了改变。以前我们需要先设定一个工作流，明确每一步的执行步骤，才能完成任务。而在未来，当智能体与人协作时，它可以自己找到其他执行具体任务的智能体。负责与人协作的智能体，首先思考我们该做什么，然后去调用那些能完成具体工作的智能体。这意味着不同智能体之间会进行协作，这种协作方式相较于当前的机械式、固定流程式配合更加灵活。这也可能是未来智能体形态与现阶段最大的不同点之一。\n\n张俊九：对，其实回顾上一代，我们主要通过APP与数字世界交互。在手机上是APP，在PC上是网站或桌面应用。而进入AI时代之后，我们与AI的主要交互方式变成了自然语言。下一代技术浪潮中，通过“发指令”“对话”或“点一点”这种自然交互方式，我们就能让AI理解意图，并完成原本需要四五个APP才能完成的事情。这种转变极大地提升了生产效率与用户体验，是一种无法逆转的趋势。至于说，这背后的系统究竟是不是Agent，或者它只是具备Agent某些特征的工作流，也许并不重要。我们前面讲到的“agentic system”概念，其实就说明了它并非一个纯粹意义上的智能体，而是一种智能协作系统。未来主流的产品形态，很可能就是这种“agentic system”。不论是人与系统的交互，还是系统之间的协作，它都将成为人们日常使用的重要方式。举个例子，未来我们可能只需要对助手说一句话，它就能自动去查找某城市的酒店和机票，从平台获取信息、比价、预订——所有这些都能自动完成。人真正只需要说一句话，就能搞定整套流程。我认为，这就是未来主流的交互与服务形态。\n\n廉和：这个过程其实很有趣。比如说，我的Agent要帮我订酒店，它是找携程？找飞猪？还是找美团？这中间其实存在很多可能性。同时，每个平台本身也可能拥有自己的Agent。当我的Agent去调用它们的服务时，怎么决定选哪一家？这其中就涉及商业化机制，比如我是携程，那我如何设计我的Agent，使别人更愿意来调用？可能通过更好的服务质量、更快的响应速度、更稳定的系统、更优惠的价格等方式来实现。这种竞争方式，和今天以用户界面为主导的应用逻辑就很不一样了。\n\n刘琼：刚刚我们谈到产品形态，我觉得这里也可以再深入聊聊。目前市面上我们看到的产品形态，我总结为两种。第一种是内嵌于基础大模型中的智能体，比如ChatGPT里的Deep Research；另一种则是独立形态的Agent，Cursor这样。我想请揭老师谈谈这两种产品形态背后的产品哲学有什么不同？它们具体体现在哪些方面？\n\n揭光发：好的。其实我理解，这背后主要是技术形态的差异。以OpenAI o3为例，用户在使用过程中可能感知不到它是一个端到端的Agent，但它其实是一个“Agent Model”。比如Deep Research就是通过o3加上强化学习训练出来的。这与过去几年我们以工程方式写代码、用“写 loop+工具调用”的方式构建Agent是完全不同的路径。现在这种端到端的智能体，技术上大大降低了工程复杂度，不再需要手动编写大量调用逻辑、调度逻辑或容错机制。这类智能体直接嵌入大模型中，可以自动知道如何调用外部工具，同时具备天然的上下文连贯性。因此在效果、效率和投入产出比上都更具优势。我们可以看到像Deep Research或o3这类系统，它们在体验效果上都非常不错。\n\n当然，这并不意味着像Cursor这种工程化Agent就没有立足之地。实际上，通过大模型强化学习的方式构建端到端智能体，其成本仍然很高。一方面需要准备大量高质量的强化学习数据，比如R1就用了600多万条强化学习语料，虽然这些语料大多是通过生成方式获得，但整个准备与训练过程的成本并不低。所以，对于大多数团队来说，直接训练一个端到端Agent model的成本是难以承受的。\n\n因此我们看到，大多数垂直类产品的Agent，仍然是通过“提示词+工程逻辑”结合的方式开发的。包括Cursor、我们自己做的一些面向运营场景的Agent，基本也是这种方式。这只是技术层面的差异；从产品体验上来看，在性能、效率和响应速度上可能会有一些差异，但整体感知不会特别显著。\n\n刘琼：您的意思是说，用户其实是感知不到这些差异的？\n\n揭光发：对，用户基本上没有明显感知。因为这确实是技术底层的一种实现方式。\n\n刘琼：那这两种形态是否会彼此渗透、双向进入？比如像Cursor，现在也有声音认为，它是具备发展为通用智能体的潜力的。\n\n揭光发：刘老师这个问题又引出了另一个关于“通用性”的分类维度。我理解通用性可以从两个方面来界定。\n\n第一个维度是物理或逻辑层面的，也就是“什么都能做”，这是一种直观的通用性。但实际上，即便是Agent，也不是无所不能，比如ChatGPT也并不能解决所有问题。\n\n因此，我更倾向于另一个维度——面向人群的广泛性。也就是说，它的适用场景虽然不复杂，但受众面很广，比如找材料写研报、问答等日常需求，大多数上网用户都能使用，这种我认为就是“通用”的。在这个维度下，像ChatGPT、Manus这类产品，可以视为面向广泛用户的通用型Agent；而Cursor则更偏向于面向程序员的垂直型Agent。但如果从技术层面来看，Cursor是否具备成为通用Agent的能力？是可以的。因为Agent的核心技术其实很简单，就是一个工作循环，不断调用工具执行任务。所有Agent的底层逻辑都是类似的。不同Agent之间的真正区别在于它们所面对的上下文。例如，一个高级程序员所需的工具可能包括编写代码、运行测试、读取文件、访问接口等，这些就是Cursor目前所聚焦的功能领域。但Cursor理论上它可以无限拓展更多工具，因此从功能上来说，它是可以向通用型扩展的。不过它需要引入不同的MCP工具来完成这件事。\n\n即便如此，大家对Cursor的基本认知仍是：它主要服务于程序员，是一个专注于代码开发的IDE(集成开发环境, Integrated Development Environment)。\n\n张俊九：我更倾向于从现实世界出发，去映射技术和产品的需求。毕竟所有技术最终都应服务于业务和实际问题的解决。现实世界中存在分工与行业，即使在一个组织内部，也会存在岗位分工与层级：有人负责设计，有人负责实现，有人负责运营。不同职能之间的专业协作往往效率更高。通过组合不同的Agent来实现协同，其实是更高效的方式。如果指望一个模型在其原生系统中就能规划所有事情，并调用各种工具自行完成任务，那就等于是我们指望构建一个无所不能的“超级大脑”式AI系统。\n\n刘琼：也就是全能型的。\n\n张俊九：对，这种全能型AI可能可以应对一些通用场景，比如查资料、获取信息等常规需求。但一旦进入某些专业性很强的领域，尤其像我们这种做To B业务的场景，需求往往是高度具体且聚焦的。这时就必须考虑解决问题的性价比。我们真的需要一个“万能”的大模型来解决这类问题吗？就好比“杀鸡焉用牛刀”。所以我认为，通用Agent和垂直Agent将在不同的场景中长期共存，这是很自然的发展逻辑。\n\n廉和：我非常认同。其实这背后还有一个更底层的问题：我们真的需要一个通用的Agent吗？目前为止，我也没有明确的答案。我认为底层大模型是具备通用能力的，但“通用型Agent”这个概念本身或许并不存在。\n\n为什么这么说？以九哥的场景为例，模型的智能程度足够了，关键问题是Agent是否知道“自己在做什么”。他是否拥有与任务相关的数据、场景（context）的认知？往往恰恰是缺乏这些信息。\n\n从我自己做产品的经验来看，模型本身够聪明，但多数时候它不了解场景（context），也不知道该执行什么任务。这种“认知空白”多数来源于数据的缺失。而数据，正是企业的核心资产。在现实中，各公司并不会将自己的核心业务数据无保留地提供给像OpenAI这样的公司。这是不现实的。\n\n另外，像我做To C(面向消费者)产品，想要服务所有人。如果我没有一个通用的底层模型，我根本没法落地任何东西。但我真正该做的是一套系统，让我无论在大模型如何演进的过程中，都能“接得住”它。同时，服务好一个人意味着，我必须“理解”这个人。因此我的数据锚点应该基于“个人”，是以人为中心的。我认为更好的服务方式应当是以人为中心的个性化服务，而不是构建一个系统，去服务全球所有用户。作为创业公司，我的目标不是再做一个OpenAI，而是服务好每一个用户。\n\n张俊九：对，这里还是回到场景导向的问题。智能体之所以区别于传统协作模式，关键在于它是“以目标为导向”的。至于中间流程是人来规划再由Agent执行，还是Agent自我规划并端到端完成任务，那只是技术实现路径的不同。但从“解决问题”的角度来看，必须考虑投入产出比。尤其是在To B行业，这不仅仅是“体验”好坏的问题，更是一个效率与成本的问题。比如说，是招一个人就能完成任务？还是需要一堆人再配上复杂的Agent系统并负责维护？这些在实际应用场景中差异是很明显的，所以我认为，最终还是要结合具体场景进行判断，Agent各有各的实用空间。\n\n揭光发：而且客户对系统的需求，往往是“稳定性”优先。目前这个阶段，我们虽然尝试接入一些外部的MCP模块，但从实际表现来看，本地部署往往是更直接可靠的选择。demo时可以尝试调动一些外部MCP，但在稳定性方面，有时确实不太敢完全依赖它。\n\n刘琼：我理解为，不同的场景，其实并不需要同样程度的智能。某些场景下，可能根本不需要高智能水平。\n\n张俊九：三百六十行，行行出状元。所以想要实现通用，关键还得结合具体场景和数据。很多数据是隐私数据、企业核心数据，它们不可接触。你让一个Agent去荒原里执行任务，它连路都没有，当然会迷失。\n\n揭光发：所以我认为，“通用性”也可以从另一个维度来理解：虽然一个Agent只解决某个功能，但它的受众范围极广。这种意义上，它就是通用的。\n\n刘琼：就是把大家的共性需求挖掘出来。那我们接下来讨论一个新的问题。刚才大家反复提到“需求”，对吧？但其实你会发现，市面上很多产品离我们的实际需求，或者说它们的完成度，其实还有不小的差距。比如我刚刚提到，我希望能有一个Agent替我写主持稿，或者能自动写稿、做PPT等，其实这些需求都存在，但现实中这些功能的完成度并不高。那么，在产品落地过程中，究竟存在哪些障碍？除了技术因素之外，还有没有其他方面的挑战？大家是否都遇到过类似的问题？\n\n张俊九：我是这样理解的，其实今天早上我还看到一个新闻，说ChatGPT-4.1解决了两个关键问题：一是任务执行过程中“中途不执行”的问题，二是如何避免“幻觉”的问题。\n\n从技术演进的角度来看，随着模型日趋成熟，这些问题可能会逐步被削弱。但从B端视角来看，不管是完成度也好，还是能否明确地完成一个客户高度接受的目标，这些因素其实才是判断它是否“可用”的关键标准。在B端的实际应用中，目前大多数业务的SOP都是被严格定义好的。系统结构是什么样的、谁来审批、字段如何填写，这些流程和标准几乎都是清晰可控的。企业真正需要的，是那些能够胜任这些标准化工作的“人”——也就是能“正确做事”的人。你无需思考太多，只要按规范操作即可。\n\n在这样的逻辑下，To B场景中的智能体应用，更多是基于既有的SOP，用来替代人完成既定任务的能力问题。比如，在财务审核场景中，最常见的就是费控审核或报销流程。你会接到一张发票、一个业务申请单或合同，然后你要从中识别大约30到50个字段，进行比对，比如检查金额是否一致、甲乙方责任、争议解决机制是否符合等等，甚至还包括发票内容的一致性问题。这些工作往往跨文本，需要精准理解自然语言，还要完成大量比对，非常繁琐重复。只要理解了审核规则和SOP，任何具备一定财务基础、懂得操作电脑的人基本都能完成。这种场景具有明确的边界，对从业者的要求就是细致认真、执行高效，我们认为这类工作完全可以交由智能体来处理。这是一类非常适合智能体切入的典型场景。而根据埃森哲的统计报告，一个企业内部平均有60%的工作是不需要动脑的，只需要正确执行任务即可。这部分工作，我认为无论是RPA也好，还是Agent也好，都应该是它们优先完成的任务。\n\n剩下的40%，是带有创造性的工作。比如像您刚才提到的，希望通过提问激发大家思考，引导整个主持思路，这样的需求就带有较强的个性化风格和情感色彩。尤其是涉及到如何围绕话题发散、引导深入讨论的能力，这些恰恰是目前阶段智能体尚不具备的。它也许可以提供一些热点话题供您参考，但它很难为您完整地写出一篇“最完美的”主持稿.不过，对于那些SOP已被定义清晰的场景，60%左右的工作岗位是可以被智能体赋能的。\n\n这也是为什么我们坚定地布局To B市场。B端的流程已经结构化，我们需要的，是那些能胜任具体工作的“人”，这部分需求正好可以成为智能体最基础的切入点。这是我对这个问题的看法。\n\n廉和：我的看法可能会稍有不同。因为我在思考，智能体这件事的“坏处”之一，确实是不太稳定，但它的“好处”在于——它可能会带来一些全新的想法。当然，我的角度可能比九哥更偏向抽象，不一定完全基于To B的实际场景。但我认为公司之所以定义SOP，是因为“怕人出错”。但在企业内部，真正解决问题或者提出创新方法的人，占多少比例？而那些只是为了服从SOP、按部就班执行的人，又占多少？这两类角色其实都是重要的。所以我思考的问题是：智能体是否仅仅用于协助人在SOP中完成细节？如果是这样，其实传统的workflow系统可能做得更好。智能体是否有可能为“那些没有明确解法的问题”提供新价值？尤其是在高阶白领的工作范围中，它也许能扮演更有启发性的角色。一开始，它未必能完全解决问题，但它可以和人一起“头脑风暴”。比如我会对GPT说，我有个想法，我们一起合计一下，它确实会提出不少启发性的建议。当然，我不能指望它把事做完，但它是一个有价值的“思维伙伴”。\n\n张俊九：对，剩下的40%的创造性工作，确实需要这种类型的伙伴。比如信息收集和整理能力更强，或者总结能力更强的智能体。它们或许无法完成一个完整任务，但它们提供的思路、信息结构、报告框架等，其实对人类工作已经是极大的辅助了。\n\n揭光发：刚才廉和提到的场景，甚至未必一定是智能体的场景，普通的大模型对话能力就可以胜任。其实，大模型在哲学、思辨等领域的思考能力，远超我们普通人，因为它整合了全球知识，它是全人类知识的压缩表达。所以，如果你想与它一起做些“天马行空”的发想，是完全可以的。这是大模型天然具备的能力，不一定非要借助Agent来实现。\n\n但回到Agent能否完成复杂任务的问题——这本身一直是个挑战，也是我们努力突破的方向。比如九哥讲到的企业级、流程复杂、需要SOP严格定义的任务，目前的Agent可能还难以胜任。但如果只是两三步、三四步的任务链，现在的Agent其实已经可以完成得相当不错了。比如刘老师刚才提到的，让Agent帮忙做PPT，甚至设计一些问题，这些事情其实是可以做到的。但之所以你会觉得它“不好用”，问题不一定出在模型本身，而在于我们怎么组织问题、怎么提供上下文。你可能需要给它更完整的原始素材、更清晰的任务目标。\n\n这正是大模型或Agent没有表现得那么好的根本原因之一——记忆管理和上下文控制能力仍有待提升。就像我们用Cursor写代码，它的能力很强，但只要与它连续对话三五轮，就会发现它“飘了”。你让它执行任务，比如写代码、进行总结，它很容易目标失焦。说到底，这就是“记忆管理”的难题。在智能体的实际落地中，这是除了“幻觉”之外，最棘手的问题之一。我今天主要想讲“上下文”和“记忆管理”的挑战。比如说，你让一个普通用户整理所有素材，交给模型生成一份PPT，模型可能初步给出一个初稿。但当你继续与它互动，要求优化这一页、修改那一页，再对话两轮，它就忘了你之前说过什么了。这才是问题的根源。不是说它在智能能力上不够——就单个模型的生成能力而言，其实已经超过人类平均水平了。不论是写代码，还是生成一页PPT内容，单任务执行上它是很强的。但一旦任务变得复杂、需要组合式执行，它的表现就会明显下滑。这其实是上下文和任务链结构的问题。当然这些问题也有对应的技术解决方案。比如你可以把上下文拆分，分配给不同的Agent分别处理不同阶段的任务。像PPT制作，你可以把每一页交给一个Agent来完成。谷歌有一个叫BigBird的项目专门研究超大上下文处理，包括DeepSeek也发了论文，关于NSA就是“原生稀疏注意力”机制，能够在几百KB乃至MB级的上下文中精确定位重点内容。这些技术都是为了解决长程上下文关注力衰减的问题。\n\n虽然目前很多模型号称支持128k甚至上兆级的上下文，理论上能做到“大海捞针”，但实际应用中，在复杂任务框架下，它们很难真正实现高目标导向的表现。不过现在确实有一些研究方向在推进，比如DeepSeek结合硬件的注意力机制优化，就是希望缓解这个问题，让模型在海量上下文中更有效地定位有用信息。当然这只是众多方案之一。你不可能每次都把所有资料一股脑扔给模型，这在实际操作中并不经济。除了优化注意力机制，还有一些方向是关于“运行时的记忆管理”。传统训练是将权重写入模型，但也有研究认为，交互过程中新学到的信息也可以写入“运行时权重”。就像人一样，今天你跟我说的话，会被记录进我原生记忆中。\n\n张俊九：就像“单步寻优”一样，每完成一段任务，就重新聚焦到下一段。\n\n刘琼：刚才我们也聊到记忆能力和上下文能力。其实你看，现在的基模也在往这方面突破。那是否有可能，随着基模能力的进化，它会逐渐“吞噬”掉很多做垂类Agent的产品？\n\n张俊九：确实存在这样的趋势。有一种观点认为：“你们都随便搞，最后都是我的。”这就像某些商业模式的竞争逻辑。当基模能力足够强时，它的吸引力就像太阳万有引力一样，所有生态都可能围绕它展开，最终甚至被它“吞并”。我认为，是否“吞并”，还要看它的商业模式愿不愿意这么做。如果它真的想，那它是完全有能力做到的。\n\n廉和：但我觉得关键还是“数据锚点”的问题。如果你掌握了行业数据，其实就不用担心被吞。基模当然会试图“吸收一切”。但事实上，行业每天都在变化。比如今天投放的广告和下周投放的广告不一样，甚至会有新的热点、新的功能。这些变化很难被基模全覆盖，尤其在深度行业领域，比如医疗、法律等。如果基模没有专业数据作为支撑，它就没有上下文，也无法做出专业回应。像办公类、报告类、市场研究类这些通用场景，基模是可以胜任的。但如果是专业部分，那仍然需要垂类Agent。\n\n张俊九：对，专业领域的问题，还是得由专业系统来解决。\n\n揭光发：是的。现在被基模“吞掉”的场景，大多数是搜索、调研这种简单任务。GPT-4o就是一个典型的风格化生成工具。以前人们可能用流程搭建图像风格转换，现在只要一句“给我一个某某风格”，它立刻能生成。这些应用场景本身就适合基模处理，因为它们流程简单、通用性强。但如果你的业务流程复杂、专业性强，那么基模就难以处理。即使想做，也必须通过强化学习或微调，在具体领域内进行二次训练，而不是依靠一个“大一统”的基模来应对所有场景。\n\n首先我们可以从场景角度来看这件事。其实在不同的角落、细分场景中，仍然存在大量的小型Agent的需求。如果我们不指望基模能覆盖这些“隐秘角落”的任务需求，那就仍然有很大的空间，可以通过“手搓Agent”的方式来实现。我认为这样的应用机会还是非常多的。所以我认为，Agent大致可以分为三种形态。\n\n第一类是在顶层的模型，也就是我们常说的基模中，Agent的能力已经被融入其中。这类模型的应用场景较为通用、普世，流量和用户量也特别大，因此值得投入大量资源进行强化学习。这样训练出来的模型在运行时Token消耗成本非常低，因为很多知识和流程已经被内化进去了，制造和运行成本也因此更低。\n\n第二类是“半模型”类型的Agent。通过微调的方式，把使用工具的plan指令、意图识别能力部分内化到模型中。它不需要通过提示词来一步步指导怎么用工具，而是已经具备基础的工具调用能力。这种方式虽然前段做了智能化处理，但后面仍需要一定的工程化支持。比如微信读书在做的就是类似这种路径。他们前端有一个意图识别模型，或一些弱路由的小模型，后端则挂着一堆工具去执行任务。这类场景中，工具库是持续扩展的，因此很难把所有工具都“训”到模型里。最高层的Agent类型是所有工具都被训进去了，比如联网搜索工具，它在训练时就已经知道该怎么使用这些工具。但像第二类这种，它的指令遵循性较好，工具仍需外挂扩展。\n\n而最底层的第三类，就是完全依赖提示词来写工具，模型对工具的使用方式是动态配置的，提示词和代码都要实时调整，工具也可能随时变更。这一类适用于小场景，尤其是在MVP阶段、流量尚未形成时，用于试错验证。这种方式灵活性大，适用于初期探索和快速迭代。\n\n张俊九：这其实是在验证Agent是否具备POC(概念验证, Proof of Concept)以及是否能解决具体场景问题。它确实是分层次的需求结构。\n\n刘琼：我有个好奇，第一类或者第二类，也就是内生工具的那类，它的工具是写死的吗？我该如何理解“内生”这件事？\n\n揭光发：其实在做强化学习的过程中，模型训练所用的数据已经告诉它应该怎么使用这些工具了。\n\n刘琼：所以它学的是“制造工具”的能力，还是“使用工具”的能力？\n\n揭光发：主要是“使用工具”的能力。在训练阶段，数据中已经告诉它要用什么工具，它学到的是工具组合的方式。所以当我们调用它时，不需要再告诉它“你有哪些工具”，它自己在训练时就已经知道并用过了。\n\n刘琼：那就是说，它的工具包是固定的吗？\n\n廉和：对的。从这个角度来说，它是“写死”的。如果它在训练中学的是一个固定功能，比如上网搜索，它就知道这个工具的功能和调用方式都是什么。但如果你让它执行一个完全不同类型的任务，它就无法完成。这时就需要我们提到的第二类或第三类Agent来扩展功能。但这就很有意思了。比如我让它写代码来实现一个工具，那第一步就是“写代码”，这本身就会引入不确定性；第二步再去调用这个工具，又叠加了新的不确定性。这样一步一步往下传导，是不是会放大问题？\n\n张俊九：对，这就像传统的强化学习中的“过拟合”问题——你提前告诉它所有的可能性，它就只能按这个套路走。\n\n刘琼：这一段我们其实聊得很深入。我们刚刚谈的Agent产品形态，其实大多还是发生在数字世界里的。但我们也有在探讨更广义的Agent，比如和硬件有关的：机器人、自动驾驶等等。还有像端侧设备、可穿戴设备等等，这些看起来也很有机会，相当于是为硬件安装了“大脑”。不过昨天我们也跟一些机器人领域的专家聊过，他们并不太认同自己被归为“智能体”这类。\n\n廉和：从“机器人”这个概念来看，特别是To C场景中，用户普遍期望机器人是一个“人”的替代者。如果按照这种朴素设想，那它就得无所不能——既能控制运动，又能像人一样回答问题。这种设想对当前技术而言，确实过于复杂。这种需求目前阶段还比较难以实现。所以我们可能需要一个“中间形态”——比如通过与机器人企业合作，一方面由专门的控制型模型来负责运动控制，另一方面用智能体模型来作为“大脑”进行认知决策。\n\n张俊九：其实AI一开始的定义，就是“帮助或辅助人完成任务”。智能体的本质也是如此——你只是换了一个更强的大脑驱动模型，同时具备了与物理世界交互的新形态，本质上还是人工智能的范畴，没有跳出这个范围。它的最终目标，依旧是“代替人”。比如说自动驾驶就是帮助人驾驶，为什么不算智能体呢？它当然也是。\n\n你比如说各种类型的系统，我觉得只要是能辅助人的，这些都可以被归入“智能体”的范畴，没必要过度纠结定义。比如过去的机械手臂，是通过强编程实现固定动作的；而现在的生产线已经具备柔性制造能力，它可以通过摄像头动态规划路径、进行智能检测等。这其实已经叠加了非结构化、非预设的一些行为逻辑，我认为这也可以算作智能体的一种。再比如自动驾驶，现在属于L1级辅助驾驶，但你能说L1就不算自动驾驶吗？我觉得也不能这么绝对。\n\n揭光发：我从底层技术的本质来谈一下这个问题。我们目前所谈的Agent智能体，更多是发生在数字世界中的，比如ChatGPT、豆包、元宝等。它们稍作升级，加入工具使用能力之后就可以被称为Agent。从定义角度来看，一个智能体通常具备以下能力：基于大模型、有自主规划能力、能够使用工具、有记忆能力，甚至能进行环境感知。如果我们把这个定义套用在机器人智能上，它其实也是适配的。现代机器人系统同样需要使用大型语言模型（LLM），如果没有这类模型的支撑，就相当于没有“大脑”。事实上，机器人智能领域的转折点也来自于大模型的兴起，它为机器人赋予了真正的“智能中枢”。其中，环境感知是机器人智能中最关键的一环，甚至比数字世界的Agent更为复杂和重要。所以“规划”（plan）能力就变得更为重要。在数字世界中，使用工具是通过调接口、读取数据、访问文件来实现的；而在现实世界中，就是驱动机器人用“手”去拿东西。两者在本质上是类似的。\n\n记忆能力在这里同样适用。因此从技术构成要素来看，本质上就是“数字世界智能体”与“物理世界智能体”的区别，差别在于媒介不同——数字世界的工具是虚拟的，而机器人中的工具是实体的，是可触摸、可操控的。具身智能中的关键点，在于它将“感知”能力作为任务执行的上下文输入，这也是它重点要解决的技术难点。数字世界的智能体，主要依靠人类语言来组织知识和逻辑；而具身智能则必须处理很多非语言的信息，如视觉、触觉等，属于多模态甚至超语言模态的信息。因此，它的能力范围实际上超出了语言模型（LLM）的范畴，也就解释了为什么很多做机器人研究的学者会认为，他们的研究范围比我们更复杂、更宽泛。\n\n但从认知决策层面来说，其实大家背后的驱动机制是一样的。\n\n揭光发：也不完全是。比如说当机器人通过触觉感知到某种物理反馈时，如果它判断可能会对人造成伤害，它可能会立刻停下来。这种反应并不是由大模型来决策的，而是由低级感知系统触发的。这类感知驱动的反射行为，更多是通过强化学习等方式训练出来的。比如机器人如何在跌倒后重新站起来，这已经不再是通过程序写出来的，而是依靠反复训练得出的行为策略。这种机制类似于人类的本能反应，不是由语言模型驱动的。这种反射类机制并不是由语言模型决策的。因此从这个角度来看，我能够理解那些做硬件的研究者，他们在某些认知层面上确实与数字智能体领域存在差异。但从更泛化的角度来看，他们的研究也可以被纳入“现实世界智能体”的范畴。他们所面对的问题更复杂、技术深度也更高。\n\n廉和：能不能这样理解：具身智能之所以在某些方面具备更强的智能潜力，是因为它能从现实世界中获取大量真实的数据。如果我们把“智能体”或“AGI”(通用人工智能,Artificial General Intelligence)的概念再往上提升一个层级，就会发现，我们目前希望模型或智能体具备的能力，很多时候之所以无法实现，是因为它获取的上下文（context）太有限。\n\n我们与智能体交互时，往往通过语言给出的上下文信息非常稀少。如果我们真的想让它具备类人智能，那就必须拥有和人类一样丰富的感知反馈。而物理世界中的感官信息，如视觉、触觉等，是非常重要的上下文来源。所有这些感知最终都会成为智能体进行决策的基础。所以说，具身智能很可能是补全整个智能体系拼图中非常关键的一块。来自实体世界的数据——包括温度、湿度、触觉、视觉等感知信息——如果能纳入其中，可能才是真正通往AGI的重要路径之一。\n\n刘琼：也就是更多模态的信息输入。\n\n廉和：是的，多模态，同时也意味着更多、更丰富的上下文。因为目前语言提供的上下文信息量非常有限。而这些实体世界中的感知，恰恰能够为大模型提供更多维度的信息。\n\n刘琼：大家应该都看到过OpenAI几位核心成员发的那篇文章，提到AI即将进入下半场。其中一个重要观点是：在AI下半场，评估模型的能力比训练本身更重要。那么在智能体领域，我们该如何评价一个智能体的好坏？现在是否已经建立了一套通用的评估标准？\n\n揭光发：大模型本身就涉及多个领域，比如翻译、编程、数学推理等。针对智能体也有一个叫GAIA(通用人工智能助理基准,a benchmark for General AI Assistants)的测试集，它确实提供了一个通用能力的评估门槛。如果你想称自己为“合格的智能体”，必须在这些测试中达到一定分数。但这主要评估的是通用能力，比如是否能使用工具、完成普适性任务，题目也不会特别偏门。但当智能体应用到企业等具体场景中，就不能仅靠GAIA这套体系来评估了。企业需要的是一套定制化的评估机制，用来判断智能体在其内部流程中是否可用。这已经成为未来发展的必然趋势。而且企业场景中，变化频繁。你可能只改动两个字段，智能体的行为结果就会发生变化。这就像软件开发中的单元测试，是为了确保修改代码时系统行为依然稳定可靠。\n\n刘琼：那大家在实践过程中，是不是也都会先定义一套标准？\n\n张俊九：从我们To B的角度来说，目前的评估标准还是在与“人”做比较，关键是效率和准确率。但如果你面对的是一个开放世界的问题，那就很难有统一的评估标准了。举个例子，二级市场的分析师写了一份研报，你怎么评判这份研报的好坏？你总不能要求投资者完全照着这份研报去投。投资是有风险的，分析师并不对结果负责。所以很多预测性的工作，不能通过结果来定义好坏。\n\n我们只能说这份研报是否在逻辑上严谨、是否引用了权威数据和多来源信息。内容客观、结构清晰就是一个质量不错的研报。但这并不代表它能带来理想的结果。所以从应用场景来看，如果我们要为智能体建立评估标准，其实也类似于考试——用问题来测试它是否掌握知识。就像中国人很会考试，AI也一样可以通过刷题拿高分。如果我们只是通过“刷题”来区分智能体的优劣，除非它算力不够，根本没学到东西，否则大多数模型的区分度会越来越低。\n\n廉和：我也非常认同揭老师的说法，题库的意义更多在于设定一个“最低门槛”。你必须要在这些通用题库中表现良好，至少不能太差。但考得好不代表就有真正的能力。接下来就会进入一个更主观的层面，比如这个Agent讲的故事更合我心意，还是另一个Agent让我更有共鸣。这种评估方式很难量化。所以到这个层次之后，我们可能根本就不该有一套“通用题库”。\n\n在企业场景里，就更该使用企业实际任务去做评估。比如我要做商品上架，那就只评估你在这个具体流程中是否做得好，和你之前在通用测试中表现如何没有太大关系。在这个场景中，我更关注的是你解决问题的方式是不是最优的，而不是你能不能答对题。\n\n当然，为什么很多人仍然使用通用测试集？主要是因为有一套标准，方便横向比较——尤其在向上汇报时，可以展示“我做得比别人好”。但在实际业务中，最关键的评估标准是：用户是否愿意为此买单。这才是最实在的评价。\n\n揭光发：GAIA这种通用测试集，就像我们的中考、高考，是对通用能力的考察。但当你真正进入某个具体场景后，就需要基于场景去设计测试机制、验收机制。而且模型评估之所以重要，还在于它将成为未来Agent“社会化协同”的基础。以前我们使用的是APP，未来我们将越来越多地与Agent交互。而且不仅是“人和Agent交互”，还包括“Agent与Agent之间的交互”。那么Agent之间的交互如何进行结算？还按照Token计费吗？比如说我生成更多图片，就赚更多Token？这种方式显然不可持续。真正有效的经济模式，应该建立在“按交付效果付费”的机制上。就像现实世界中，A公司给B公司完成一个项目后，只有交付结果符合预期，才会收到付款。这其实就是一种“合同制”协作机制，而合同的背后必须有一套可验证、可评估的标准体系。目前这一体系在Agent生态中仍属空白。\n\n廉和：还有一个可能的问题是，测评的结果本身仍然非常重要，特别是在如何利用这些结果进一步指导研发方面。比如说如何去优化我的智能体、我的模型，或者它的运行机制等，这其实是一个非常关键的点。当然，我认为其中仍然有许多问题需要厘清，才能确定研发的方向。\n\n刘琼：对，我其实还挺好奇，谁会最有动力去推动这件事？\n\n揭光发：做生态建设的企业，或者一些创业公司会去做。因为整个生态还刚刚起步，像Agent to Agent（A2A）的交互协议刚开始形成，所以先看到这一趋势的企业，通常会比较积极参与。它现在只是一个互动协议的雏形。\n\n现实世界中，人和人之间的沟通，比如打招呼、加好友，并不是随便聊的，而是基于一定的熟悉度与机制来展开的。同样，Agent之间的交流也会包括任务协作、任务验收，甚至包括Agent与Agent之间的支付机制。这些都属于新的业态，需要新的基础设施支持。一些大厂可能会进入这个领域，同时也会有不少小型公司，尤其是创业公司去布局。比如我前段时间就看到一个国外的小公司已经在做Agent间的支付确认机制。所以说，这是一个全新的业态，它实际上是在将人类社会的组织形式和协同逻辑复制到Agent世界中去。它是一个确定的趋势，而且我们已经能够看到这一趋势正在发展。因此，创业者也好，大厂也好，都会投入其中。\n\n刘琼：你刚刚提到A2A，那我们是不是也可以聊一下MCP？因为其实大家一直都在讨论，MCP是否会成为智能体未来的底层基础协议，是否真的重要到这种程度。另外，MCP是否适用于所有场景？我们昨天也聊过，可能对C端合适，但对B端未必。\n\n张俊九：我觉得既然把MCP定义为一种“完美”的协议，那它最根本的目的就是为了解决异构系统之间的通信问题。所有协议的初衷其实都是如此。在一个分布式网络中完成协同与交互，确实是必要的。但MCP的一个不足之处在于，它会引入额外的复杂性。就像大家都讲中文，却非要通过一个“国际语言”进行中转一样，有些时候显得多此一举。尤其在一些私有化、小型系统或封闭环境中，如果大家分工明确、结构清晰，其实没必要用这么重的协议。MCP带来的开销包括 server host、发现机制、路由机制，以及通信消耗等等。\n\n在这种封闭场景下，如果我知道我要去了解一个To C的信息，我直接调API就可以了，根本不需要再经过一层发现机制或中间转换。所以从高效性和经济性角度来说，在没有足够多通信对象的情况下，完全可以直接通信。作为To B从业者的视角来看，我觉得没有必要为了MCP而去MCP。但在一些开放性领域，或者竞争充分的领域，大家在同一个平台上竞技时，如果我提供的服务比别人更高效、更便宜、更好，那么MCP这种开放式协议可能就有价值了。它能够作为一个丰富生态的方式，让各方都能遵循同一个标准，从而补充Agent的能力。目前已经有很多人在做这方面的尝试了，我是这样看待这件事的。\n\n廉和：我很同意刚才说的，如果是一个封闭环境，我直接调API就能搞定。但是如果是一个屋子里有一万个service，我该用谁？这时候就必须有一套机制，来对这些Agent进行评估和选择。\n\n这个机制就得建立在统一标准之上。我反而觉得现在MCP还不够重，它虽然解决了通信问题，但并没有统一标准。我们还需要基础设施，去定义如何在这1万个Agent中更有效地找到最适合执行任务的那个。而且这个Agent找到之后，还要能保证它执行得好，符合我的需求。这些标准MCP目前都还没定义。我反而觉得，它应该更重一些。有了标准，我们才能互相比较。也只有在有标准的基础上，才能做工程化优化。不然，我连该填什么字段都不知道，也不知道怎么给你做加速优化。一旦这些标准确立之后，我们甚至可以构建一个Agent的市场机制。用户可以在里面进行搜索、排序、筛选，这会打开新的可能性。\n\n张俊九：但我担心MCP最后可能会变成“王婆卖瓜”，因为它完全是通过自己的描述来自我推荐。\n\n廉和：所以规则的制定不能仅靠描述，还得加入更多维度。\n\n揭光发：这也意味着，如果真的建立起一个市场，那就要引入用户的投票、评价机制，让人类的判断也参与其中。实际上MCP的官方团队已经开始准备推出registry，虽然现在还没有正式版本，但社区已经出现很多类似的找MCP server的网站。MCP最早其实是Anthropic为了解决自己客户端场景的问题而开发的协议。它的最初设计目标是服务Claude Desktop这个场景去开发了这个协议，它最早的初心是为了服务客户端的Agent。客户端的一个典型特征是更新困难，比如你发了新版本，用户不一定会主动下载。因此MCP内部集成了prompt加载和资源加载机制，对于软件更新来说特别有用。另外，MCP当时提出的server，其实是鼓励运行在客户端的。也就是说，如果你想跑一个MCP server，你要先下载一个包，在本地启动它。本地server启动之后，Agent就通过API调用的方式去完成任务。这种架构非常适用于To C场景——单服务、单用户、单进程。但如果到了To B的场景，你就会发现一个问题：单进程根本无法满足服务需求。\n\n你要扩展成多进程，就会遇到新的难题。比如同一个用户的两个连接落在两台不同的机器上，你该如何实现这两个连接之间的通信和路由？这又是一项很重的工程。所以说，MCP对于To C场景是非常友好的。但到了To B，它原有的协议架构就变得过重、难以落地。你本来只需要调一个接口，现在却要建立连接、进行SSE推送、部署消息队列集群，来维护多个节点的状态。你会觉得：“我图什么？没必要为MCP这三个字吃这么大的苦。”但从C端用户的角度来看，MCP的好处就在于它是完全用户导向的。用户可以根据需求选择不同的MCP，实现差异化满足。\n\n我们再回到MCP，它最早其实是为客户端、To C端的Agent设计的，所以它对于C端用户而言，是有很多优势的。刚才我们也提到通用智能体的概念。所谓“通用智能体”，我们希望它能完成所有事情，对吧？但实际上，即便是像OpenAI的模型，或者未来元宝支持了工具调用，它是否就能完成所有事情？其实并不能。它内置的工具——也就是官方提供的，可能就只有那么几个，比如使用浏览器、访问电脑等。如果你想要实现一个真正意义上的通用智能体，还缺少什么？缺工具。而如果客户端支持MCP，外部有大量的MCP工具可以调用，用户就能选择所需工具，这时候客户端便真正具备了“通用”的能力。这个“通用”不是靠自身，而是依靠大量外部工具，来扩展能力，实现“什么都能做”的目标。\n\n我举一个比较生动的例子。我们现在用Claude写代码，在没有任何MCP工具接入之前，你可能只能让它帮你写一段代码。比如你说：“帮我写个需求”，它写完后，你还需要自己打开任务管理平台，手动切换任务状态，推进测试流程等。但如果接入了腾讯的TAPD工具，并通过MCP将TAPD挂载进来，你就可以直接对Claude说：“帮我看看今天有什么任务分配给我，并帮我解决。”这时，Claude就会通过MCP与TAPD系统通信，找到开发需求，将其呈现出来，然后写代码、提交，并自动关闭任务。这一整套流程就完成了。这正是通过MCP接入外部工具，让原本只能写代码的智能体，实现了从接需求、写代码，到完成任务推进的一整套工作。这一过程大大扩展了AI的能力，使其朝着“通用”迈进。\n\n因此，在C端、面向个人用户的应用场景中，这类协议是非常有必要的，效果也非常明显。而回到To B的场景，To B用户的诉求在于统一工具调用规范，但MCP在当前的服务端、搜索端环境中并不够友好。后来，MCP也推出了一个新版本的协议叫Streamable HTTP，是基于无状态（stateless）的版本，但大家可能还未真正注意或使用。所以，这就是MCP的一个发展背景，也体现了这类协议在不同场景下的适用性和局限性。\n\n刘琼：我追问一个小问题：国内目前围绕MCP建设生态的情况如何？刚才廉总也提到，MCP还不够丰富，那国内这块参与多吗？\n\n揭光发：有一些民间开发者确实在做MCP相关的发现服务，比如“MCP.so”就是一个典型案例。民间肯定会有所动作，毕竟市场有这个需求。但一旦官方下场，势必会对这些服务产生影响，尽管未必是直接冲击，但影响还是存在的。如果官方做了类似的服务平台，那“卡脖子”就会更容易实现。协议本身你是无法卡我的脖子的，我的代码可以照这个协议来写。但如果你掌握了“服务端”的发现机制，那我必须在你的平台上进行资源发现，这就可能被卡住。\n\n刘琼：也就是说，核心问题仍然在于“谁定义规则”。\n\n揭光发：对，它其实是这样的。就像某些国外平台一样，如果他们真的去做发现服务，比如像App Store一样，本身Claude在国内就是无法使用的。你认为他们的MCP的registry能在国内使用吗？肯定是用不了的。所以说，国内这类社区形态下的MCP工具发现服务，是确实有存在空间的。或者换个角度，国内有没有公司或者组织可以来做“国产版”的MCP？这未必一定就是由MCP来承担的。我认为，其实可以稍微调整一下思路：国产版未必完全等价于MCP，它只需要在工具发现和调用这一层面实现兼容，其实就已经足够了。\n\n实际上，大部分MCP的主要功能，确实就是用来做工具的发现与调用的。除了官方工具——比如官方提供的浏览器或文件管理插件之外，它们虽然做得越来越重，但绝大多数开发者并不会用那些复杂的部分，主要就是用MCP来调用工具。\n\n刘琼：我们接下来聊一聊商业化问题，这部分可能需要分情况分别探讨。先问问九哥，其实你看，在移动互联网时代，To B本来就不是一个特别性感的生意，需求比较细比较散。那你觉得在智能体这个新的赛道里，这些问题是否依然存在？还是说它可能会带来某种颠覆，或者有机会重塑To B的商业逻辑？\n\n张俊九：从我们当前服务的客户画像来看，可以大致分为两个市场：一个是国内市场，一个是国际市场。国际市场内部还需要进一步区分，比如欧美、日本、东南亚等地区也不完全一样。无论是国内还是国际，To B 的商业逻辑始终是从客户需求出发：你到底帮客户解决了什么问题，带来了什么价值？投入产出比是否合理？是否能提供系统化的解决方案？AI也好、智能体也好，或者传统的IT服务也好，本质上都是通过工具或系统来帮助客户解决问题。\n\n从这个逻辑出发，目前我们对Agent的定义还没能达到“颠覆性”的程度，尚未能够彻底重构客户的业务逻辑。现在更多是基于客户现有的业务流程或SOP，通过智能体来提升效率，尤其是在一些以往技术难以解决的问题上，确实取得了突破。比如在处理非结构化数据方面，大模型的效率显著优于传统模型。例如以前做文档审核和文本抽取时，需要大量标注素材来训练模型；但现在，由于基模能力大幅提升，对于通用的文字理解、文档阅读、关键词抽取等能力已具备较强效果，不仅提效，而且成本也较可控。\n\n其次是协同模式的变化。以前AI更多解决的是单点问题，比如OCR、NLP里的情感分析等。而现在，通过workflow方式，我们能把多种能力串联起来。这在To B场景中，可以有效替代或辅助各岗位之间的协同，从而降低实施成本。例如，以强模型为底座构建出的各类Agent，不仅能实现人与信息系统之间的高效交互，也能在不同岗位之间形成更紧密的协同。\n\n第三点，在工作范式上也可能发生转变。过去的组织是按岗位和业务职能划分的，各岗位各司其职，通过信息系统协同。但未来可能会以“目标”为导向进行协作，也就是说，为了完成某一任务，逐渐淡化岗位之间的边界，从而在生产关系层面引发变化。比如未来可能会出现“指挥Agent干活”的岗位。这在制造业尤为典型，比如黑灯工厂——不需要开灯的自动化工厂，产线工人被机械臂取代后，反而对生产线设计和高水平管理人才的需求增加。同样的趋势也可能出现在办公室场景中。例如我们某客户的财务共享中心，通过引入智能体，最终实现了约三分之一的人员转岗。过去需要多人协同完成的重复性任务，如制单、复核、审核等，现在只需要一个智能Agent就能全部覆盖，最后只保留一个人工岗来处理特别敏感的信息字段即可。这无疑是对生产关系的一种改变。\n\n从国际市场来看，和国内情况有所不同。我认为国际市场的空间可能更大一些。To B出海成为这两年热门话题，原因在于它有一个基础性优势：相比国内，国外的信息化标准更高，定制化需求更少。海外客户普遍接受SaaS(软件即服务,Software as a Service)模式、效果付费，也更认可“用信息系统节省人力”的价值逻辑。再加上国外人力成本本就较高，因此他们的付费能力更强。这一点在我们进入日本市场时也得到了验证。所以总体来看，国际市场的商业变现路径更清晰，空间也更大；相较而言，国内的To B发展路径确实要更为曲折和复杂。\n\n从技术本身来看，Agent的落地确实会带来生产力的提升，同时也对现有的生产关系产生深刻影响。\n\n刘琼：这是个“时间问题”吗？\n\n张俊九：我认为这是个“规模问题”。从0到1可能较为困难，但一旦跨过门槛，从1到100会发展得非常快。\n\n刘琼：两位老师是否还有不同看法或补充？\n\n廉和：我认为，C端的核心在于，Agent带来了一个新的变量，这个变量本质上是“入口型”的变量。以前我们在手机上使用APP，每一个功能通常对应一个独立的应用，我们需要点击相应APP才能完成任务。但如果有了Agent，它可以理解我的需求，然后主动去寻找相应的功能来实现。在这种情况下，我就不再需要打开那么多不同的APP，只需要告诉这个Agent我想完成什么，它就会代劳。这个Agent可能是一个对话框，也可能是语音交互，但未来它不一定仅限于这些形式。因为人类的交互方式本身就多样化，比如视觉、AR/VR设备，甚至未来可能包括触觉等感知方式。以往，不同的任务是由不同的APP、不同的公司提供的，现在则可能是由一个统一的公司来满足我所有的需求。这种集中化的入口形态，将成为一个高度竞争的焦点。各大公司和头部厂商都可能参与到这个入口的竞争中。比如手机端侧的入口就可能成为一个极具力量的流量汇聚点，这对现有的商业模式将构成巨大冲击和转变。\n\n以前我们查找APP或服务的方式，就像早期的门户网站，用户需要在门户首页逐层点击：体育→NBA→球员等，是“人找信息”的过程。未来在有Agent的情境下，服务也将如信息一般“主动找人”。过去我们需要一个个打开APP，再决定要使用哪个服务。现在只要通过一个统一入口，Agent就可以在后台对接其他Agent，完成任务。这种服务的传递模式也将带来商业模式的重大变革，比如如何计费、如何付费等问题。\n\n刘琼：那你是否认同这样一种判断：未来的“超级APP”，将诞生在智能体领域？\n\n廉和：可以这么讲，或者说未来的超级APP，本质上都会是智能体。\n\n刘琼：是的，我们刚才也探讨了，未来的主流形态就是智能体。\n\n廉和：是的，虽然智能体的表现形式可以是多样化的，但它不一定是目前这种单一的对话框交互。\n\n揭光发：确实有可能，未来的一个超级智能体就是一个桌面或手机上的对话框，它支持用户自由加载工具，进而完成各种任务。从某种意义上讲，这样的Agent就是通用智能体，也就是“超级入口”。\n\n我也从用户角度来谈一下商业化的问题。你们都从公司层面出发，我来谈谈用户视角。\n\n首先，在国内，C端用户的付费习惯其实并不强，尤其是在软件或SaaS服务方面更是如此。以前很多做SaaS的企业在国内基本收不到费用，真正能实现收费的极少，哪怕是电商相关的SaaS服务也很难推广。但AI的到来改变了一些事情。比如AI编程这个场景，现在还有多少人没有购买Copilot或Cursor这样的产品？没购买的，大多是还没有感受到这股压力，凡是稍微敏锐一点的用户，几乎都会愿意花钱购买一个智能体账号，以提升编程效率。无论提效幅度是50%还是100%，只要能提高效率，人们就愿意为此付费。AI真正做到了为个人用户带来可见的生产力提升，因此他们才愿意付钱。关键在于，用户必须认同这个AI或Agent所创造的价值。这种价值要么体现在效率提升上，比如将本来需要100%时间完成的任务压缩至20%，剩下的80%拿来摸鱼；要么体现在陪伴体验上，每天陪伴用户、提升情绪状态。\n\n国外的情况则不同。他们本身就具备较强的付费意愿，且拥有更强的模型底座。例如你在国内落地AI，可能只能接入少数几个模型；而在国外，像Manus创始人肖弘曾说，最适合用来做智能体的模型是Claude 3.7。我其实也认同这种说法。智能体讲求逻辑、流程、规划，这和编程能力息息相关。Claude在编程领域研究深厚，效果也显著好，因此基于它构建的智能体自然表现更优秀。国外用户付费意愿强，加上模型能力好、生态成熟，因此他们的商业化路径相对更顺畅。\n\n现在很多国内创业者，一开始就选择服务海外市场，这也是基于同样的逻辑。To C的智能体基本上都是先从国外起步的。我还想分享一个小感悟：我刚才提到，AI编程这种面向开发者的工具，其实已经成为AI时代To C收费的第一波。我曾经在进入腾讯前，做过低代码创业，当时就有朋友劝我，不要做开发者市场。那时我听从了建议。但现在AI来了，我犹豫再三是否再试一把。结果就是，这次听话反而错失机会。虽然这是一句玩笑话，但它也说明，AI的到来确实颠覆了很多我们过往的认知。\n\n廉和：对于大多数非编程用户来说，他们其实尚未真正感受到AI的冲击力，在这些用户看来，比如情绪价值类的应用，他们还是不太愿意付费。国内用户更多倾向于接受广告支持的模式，即便在陪伴型应用中，愿意真正付费的用户也是少数。大多数人宁可看广告，也不愿意掏钱。即使在陪伴赛道，核心用户中真正付费的也是极少数。\n\n如果回到广告逻辑，我觉得未来Agent-to-Agent的范式，会孕育出新的广告空间和广告形态。以前广告是嵌入在APP中的，由人点选，从而进行计费。但现在，如果Agent要调用服务，那这些服务就会进行某种形式的竞争。比如用户要订机票，是用携程、飞猪，还是其他平台？这些服务之间会在Agent层面进行比拼。这种Agent间的交互过程，也同样可以成为广告的新场景。虽然现在还没有出现这类模式，但未来，尤其是在To C的大流量系统中，这很可能会成为一个重要的方向。\n\n揭光发：对，To C还有一个风险，尤其是在国内市场——就是大厂可能会把你“折叠”掉。\n\n这是个非常现实的问题。你看像Deep Research功能，国内所有的大厂，包括豆包在内，也都推出了自己的Deep Research社区产品，而且全部免费开放给用户使用，像ChatGPT这种付费模式在国内不存在。\n\n既然提到了商业化，那我就接着讲刚才提到的A2A(Agent to Agent)模式。A2A，或许会带来一种全新的商业业态，也就是我们常说的“Agent的社会化协同”。这种形态类似于人类社会中“人和组织”“组织与组织”的协作机制——这些模式，未来在Agent世界里也都会被复制一份。这其中其实存在很大的商业空间。\n\n张俊九：我们之前也探讨过，在真正的“超级智能体”诞生之前，现阶段存在一个“过渡阶段”。这是当前许多传统应用服务商正在思考的问题。也就是说，所有软件在作为入口的同时，也在考虑如何叠加Agent功能、AI功能。我们能看到，很多软件现在会推出一个“升级包”概念，即：你开通会员或在已有付费基础上再支付一笔费用，就可以获得Agent功能的叠加。比如在WPS中，现在就有类似AI助手的功能；又比如钉钉，它推出了365会员服务；再比如像淘宝或京东这样的购物入口，系统会根据你的喜好，为你推荐新品或相似风格的生活服务。这种方式虽然不是以“超级入口”的形式呈现，但它在用户没有明显感知的情况下，也能满足潜在需求。实际上，很多用户在浏览过程中，才突然产生某种需求——这种“贴身服务”的模式也是非常重要的。我们在业内交流中也探讨过，AI大模型或Agent能够将原有的业态或服务，转变为“更好的服务”。这恰恰是当前各大互联网厂商正在布局的方向。\n\n廉和：但另一种选择就是，我完全可以切换到另一个软件，再搭配GPT使用。虽然整体体验可能稍差一些，但如果GPT的AI能力远远超出你内嵌助手的能力，那我可能最终就不用WPS了。这种可能性是存在的。\n\n刘琼：那是不是就要先用AI占领用户心智？\n\n廉和：没错。\n\n刘琼：这种情况主要发生在C端？\n\n张俊九：对，我认为在To C领域，用户体验是第一位的。你让一个用户跳出软件，再用两个软件进行协同，还不如在一个软件内一站式完成任务。\n\n在B端，我们目前看到的趋势是“能力嵌入为主”。比如，在用户现有的工作流中嵌入一个链接或对话框。这种方式我们称之为“软切”。也就是说在原有工作习惯和操作界面不变的基础上，提供额外的辅助能力。这样既不影响原有系统，又能贴合现有使用习惯。在B端，对错误的容忍度极低，一切都必须稳定可靠，很多任务还要用KPI来考核。所以，在这种背景下，B端更倾向于选择那些“熟悉的、习惯的、可控的”模式。哪怕Agent已经能完成任务，他们仍然希望“看着它在干活”，以获得控制感。这种需求就促使产品设计为“准实时交互”。这其实体现了B端产品的逻辑。如果你突然告诉客户：“你只需要扔个需求，等着结果就好”，这对客户来说是一种“完全无人操作”的新模式，信任门槛太高，现在还难以接受。\n\n揭光发：不过趋势确实在向这方面发展。过去我们说交互是“结构化交互”，未来我们在做B端新需求、运营系统新需求时，如果能够“无界面”，我们就尽量不提供界面。如果一句话或一个按钮就能表达清楚，那就用这种方式来实现。\n\n张俊九：我们把B端场景分为两类：第一类是需要高频交互的copilot模式，这类任务适合Agent作为“辅助工具”；第二类是“无人值守”模式，适合一些标准化、流程化、经严格设计的任务，这些任务可以完全放到云端运行，用户只需查看结果。如果是实时交互类任务，那就更适合在本地桌面上，提供类似副驾驶的辅助功能。这两种模式不冲突，反而是互补的。如果是一些长流程任务，像我们现在体验的一些Agent产品，一个完整任务跑下来可能要花十几分钟甚至二十分钟。在实际工作场景中，如果让我一直在桌面上等着，那体验其实并不好。所以，短任务可以实时交互，长任务则可放到虚拟机或云桌面中，两者协同是更合理的模式。\n\n廉和：这是不是也和现在Agent独立完成任务的准确率有关？\n\n张俊九：有很大关系。在我们的To B服务中，目前仍是“工作流驱动”为主。当然也存在一些长尾场景，可以做到端到端处理，比如一句话输入，然后等待结果。这种情况我们一般通过外挂知识库的方式进行强化：即在一个封闭场景中，通过知识库为其提供上下文支持，让它知道每条指令应该遵循哪些运行规则、判断标准、审核逻辑等。我们更多地是在“使用模型的能力”，而非“依赖模型的知识”。在To B场景中，我们不能让大模型的“知识”直接进入我们的工作流，只能使用它的“能力”。\n\n刘琼：那像这些原生类智能体或者AI，你们有没有一个对它“真正爆发”的时间预判？什么时候它们会大规模涌现？\n\n张俊九：挺难的，我只能说确实挺难的。从To B场景来看，我们接触过的客户既有行业属性，也有具体场景的差异。举例来说，中国的财务系统虽然统一遵循中国会计准则，但由于各自业务不同，导致在科目设置、报销流程、审核规则，甚至财报分析标准上，都存在差异。这些个性化需求是无法标准化的，即便准则一致。因此在To B场景下，每个客户的个性化定制非常强，最终导致AI的实施成本非常高。这是我们目前在To B场景中面临的一个问题，目前也没有特别好的解决方案。\n\n当然，如果未来工具的封装程度和准确率能达到一定水平，是否可以通过咨询+培训的方式，把使用权交还给客户，由他们自己使用？我更多希望聚焦在平台的搭建，以及一些Demo场景或复杂场景的服务上。让客户自己能够在这些场景中用起来。这也对应了我们现在经常提到的一个概念，叫“Agent boss”——每个人都成为各种Agent的调度者，由自己指挥一群Agent来完成任务。我觉得不论是To C还是To B，这个逻辑都是一致的，前提是你的Agent必须具备强大的基础保障能力。\n\n廉和：我认为，如果放在时间维度上来看，Agent本身仍是一个技术驱动型的形态，\n\n第一个观察点是“基础模型能力”需要上一个台阶。当前大家在使用Agent时之所以觉得难用，是因为我们无法确定它的回答是否准确。如果我们能将幻觉率降低一个甚至两个数量级，当基础模型能力上升到这个水平时，Agent可能就会自然迎来爆发。大家现在都已经看到了Agent的promise一直都在，只要它能稳定运行，它就一定能用。因此Agent能否迎来爆发，关键在于基础模型能否把幻觉率压下去。如果未来GPT-5或其他模型能大幅降低幻觉率，那或许就是一个爆发点。\n\n第二个观察点是“数据上下文（context）信息的收集方式”。我们刚才也讨论到这个问题，目前模型只能通过自然语言的方式来接收上下文信息。但未来是否可以通过更完整的方式，比如多模态输入，甚至是硬件协同，在To B或To C场景中为Agent提供更有效的context？如果能实现这一点，Agent的能力也将再上一个台阶。\n\n这两个观察点的先后顺序不好说，但每一个都可能成为Agent爆发的关键因素。\n\n揭光发：可能对于大众而言，大家今年才刚刚听说Agent这个词，我们在这个方向上已经做了两年。如今它逐渐进入大众视野，并引起广泛讨论，说明这项技术已经达到了六七十分的成熟度。\n\n刘琼：它所覆盖的其实是我们过去未曾设想的一些场景。现在很多情况是：我有这个需求，但过去没有一个合适的方案来满足我。现在Agent正是在填补这个空白。\n\n揭光发：我理解。这个时间节点其实也符合我们之前的判断——从开始投入到大众广泛认知，大概需要两年左右。有观点甚至预测，2027年左右将是一个临界点。虽然这个观点可能显得有些“血腥”，但他预测到2027年，大部分白领类工作将可以被“折叠”。其实这个速度真的会比我们想象得更快。当然我们不是说，要把To B场景下所有复杂系统都彻底革新，但对于大多数小白领所从事的日常文书工作、文字处理工作，甚至一些跟进性质的任务，AI的确已经具备完成这些工作的能力了。\n\n张俊九：Agent的爆发可能会首先出现在To C端，而在To B端的深入应用，则可能像这是由两个主要因素决定的。\n\n第一个因素，是企业现有的系统资产。这些系统作为固定资产投资，其寿命还在。企业无法轻易绕过这些历史系统与数据。比如我们某家头部金融客户就提出，要我们为其客户经理团队构建一个全新的智能知识系统。他们不需要传统的信息门户或业务系统，只要求一个简单的交互界面，比如对话框，能实现核心能力即可。这种需求完全不同于传统系统，它可能会在一些新场景中快速迭代出来。\n\n第二个因素是，大量老旧系统甚至连API都没有，更别说做什么自动化封装了。在这种情况下，只能通过人工在UI上操作。这就意味着，对于我们做RPA的企业，仍有生存空间。我们可以在原有的执行流程上进行跨系统、跨软件的操作，模拟人的逻辑去提取和处理数据。由于当前系统现状，这个坎还暂时无法跨过去。\n\n第三个因素是我们此前反复提到的问题：我们无法为智能体提供足够好的上下文和基础数据。这使得智能体效能难以完全发挥。而在B端，不同企业之间存在数据封闭、场景差异等现实限制，无法像C端那样共享开放信息。而整个产业链的协同，则需要更长的周期来完成。所以从B端角度来看，Agent的落地速度注定会更慢一些。而从商业化爆发的角度看，To B的周期也会更长。\n\n廉和：同意，我的B端可能还有一些介于B端和C端之间的，比如我公司特别小，我肯定没有上财务系统，也没有上各种各样其他这种系统。比如说我不会去专门找一个大律师，给我去审我的小合同，合同一共才没几个钱对吧？但是这种时候，我看现在有很多新的基于AI的软件，可以帮我审合同，或者说可以帮我去看一下我的财务内容。\n\n张俊九：这种属于服务类的替代。\n\n廉和：对，这种其实觉得还挺好的。\n\n张俊九：服务类的替代，确实相对比较多。比方说我以前，可能有很多outsourcing的设计、人力服务方面的设计，比如说帮我筛选简历、组织招聘会等，这些东西确实是服务类的。我们把它统称为BPO(业务流程外包,Business Process Outsourcing)，我把这块业务外包给你了。\n\n廉和：对对对。\n\n张俊九：对于这些提供BPO服务的行业来说，这是个利好。他们以前是用人工完成大量工作，现在则可以用一堆Agent或者机器人来达到同样，甚至更好的效果。对于这些企业而言，他们的竞争力将会提升。比起同行能走得更快，提供服务类的企业可能会率先成为被颠覆的行业。这块已经非常成熟了，我们现在也在做。\n\n刘琼：这是我们接下来要谈的一种新的商业模式Agent as a service，对吗？\n\n张俊九：是的，是一种service。因为BPO这个行业，它服务的大B客户，本质上是乙方的角色。乙方可以通过工具的不断迭代与升级、服务模式的进化，以及提升“机器人密度”，来提供更高效、性价比更高的服务。最终来看，它没有本质弊端，因为整个链条是供应链体系，核心企业进度相对慢一些，而围绕其服务的公司可以走得更快。\n\n我们现在也在开拓一个稍新的赛道，就是做“数字员工”。我们把它统称为数字员工，核心就是通过技术手段，替代人工完成某些业务。从这个逻辑出发，我如何提升数字员工的性价比？靠的是大模型驱动，融合RPA的跨系统操作能力，综合起来实现比传统BPO更高效的服务。我们提供的是“数字员工服务”，也就相当于成为了新时代的BPO公司，发展方向大概就是如此。\n\n刘琼：你这边是怎么计费的呢？\n\n张俊九：我们会根据节约的人工成本按比例计费。比如说你以前用一个人，一年花10万块，那我5万块你愿不愿意？如果不愿意，2万块，看客户规模和需求。\n\n刘琼：现在客户的接受度怎么样？\n\n张俊九：对，客户的接受度很高。难点主要在于服务To B过程中，如何控制自己的成本。第一是个性化定制仍然存在；第二是运营成本。因为我们不可能通过系统实现所有自主决策，现实环境在变化，规则在变化，系统可能也会有调整，这时候如何将运营成本控制在合理水平，就变得至关重要。总的来看，这是机遇与挑战并存的，一个新技术的到来，永远是这样。\n\n刘琼：揭老师怎么看这种模式？\n\n揭光发：它确实是一个大的趋势。因为我们一直讲，Agent是未来主要的人机交互形态。除了“人跟Agent”，我们也一直强调“Agent对Agent”。其实不管是哪一种，背后都是Agent这种形态在支撑。过去的SaaS是提供一套结构化的软件界面让人来操作；而现在的AI已经可以理解人的意图并帮你自动完成任务，这就是一个不可避免的发展趋势。但关键在于，这种模式到底如何收费、如何计费，是值得探讨的。对用户而言，除了最基本的API调用方式，我们不可能对终端用户按Token来计费。又回到了老问题——包月制？还是按效果付费？这些都是不同的商业模式。\n\n但我觉得，对于直接使用者而言，如果是面向终端用户的Agent，包月可能是合理的；但如果是Agent对Agent，在背后自动执行的服务，那我不是每天用、不是每月用，可能是按次调用，那又该怎么收费？继续按Token计费？这可能不是一个很健康的商业模式。接着又会回到一个问题：如果是按效果付费，怎么界定效果？怎么评估这个Agent是否真的完成了任务？是不是要引入第三方作为仲裁方？提出各种评估标准？\n\n张俊九：这就比较麻烦了，涉及成本太多。这还得算在运营成本里，包括你的知识投入、人力投入等等。\n\n揭光发：所以这是一种可能性。要么就是我们制定统一的评估标准。但到了Agent对Agent的自动执行场景时，就不像人工验收那样可控。坦率地讲，很多To B合同的验收，其实是“差不多就行”的态度——功能跑得通、稳定性尚可，就签字。但Agent产出另一个Agent的结果时，那确实存在很大的不确定性。不过这也意味着，这里面还有想象空间可以探索。\n\n刘琼：感觉往规模化发展，还有很多障碍需要克服。\n\n揭光发：的确有很多障碍，但趋势已经非常清晰了。哪怕前期某些环节需要引入人工参与验收，整个Agent体系也能跑起来。换句话说，就是先“人机混合”再逐步过渡。\n\n刘琼：接下来的问题是，我们刚刚也聊到像编程类的Agent产品确实大幅提升效率，但它同时也带来了很多增量需求，尤其是在服务这一块。比如说以前可能不是所有人都需要编程，但因为AI降低了门槛，现在可能连我也想学一学，不一定是要去大厂当程序员，可能是出于其他目的。这些新增服务需求，未来是继续由人来满足，还是说可能会有不断进化的Agent来提供？大家怎么看这种趋势？人和AI之间的分工，会往什么方向走？\n\n张俊九：我们在做的产品，是一个垂直训练的大模型，叫塔斯，67B的。你看《星际穿越》的时候，会发现里面真的有两个机器人，一个叫塔斯，另一个叫什么我忘了。这两个机器人，其实已经变成你的伙伴了。未来，学习的主导者是谁，其实没那么重要了。传统教学可能更生动、更有亲和力，但现在你会发现，像刚才廉总说的，他要教小孩学英语，其实也可以通过AI标准化地实现。它有内容生成能力，也能根据学习水平进行评估，比如发音准确性等等。这就说明，人教还是AI教，已经不是核心问题了。真正的关键是：你有没有内驱力去学习。这其实已经是“生产力变了”，而“生产关系”就取决于你掌握新工具的能力。如果你掌握得好，就能很好地与AI协同配合。\n\n其实我个人觉得，从现代社会的发展趋势来看，以AI为主导的趋势更加明显。对人的自学能力和碎片时间的利用能力，要求也更高了，不再是集中式、课堂式的学习交互。实际上，现在孩子的学习也是这样的。我不知道你们的感知如何，反正我家两个孩子中，老二的学习方式就是，虽然也有老师授课，但更多的是他和各种工具之间的协同。最早是用毛毛虫配合朗读，现在已经可以通过AI软件进行复读训练——AI读一遍，他跟着读，还能根据学习能力智能出题，安排互动练习。这些其实都是教育类AI产品的体现。你把这个逻辑延伸到其他领域和场景，基本上也是类似的。像以前那种“从小白到精通”、“21天速成课程”的模式，现在可能会逐渐减少。最终会演变成类似打游戏闯关的逻辑——你能闯到第几关，就意味着你具备了什么样的能力，能胜任什么样的系统操作。AI的这种交互式培养、学习与成长，可能会更普遍一些。\n\n刘琼：您的意思是，未来可能是人机协作，共同满足这个增量市场的需求？\n\n廉和：确实这是一个很明确的Promise，也就是说，我们必须学习的内容，是可以高度流程化处理的，它可以根据你的需求进行适配。只是目前还没达到那样的程度，但这个愿景肯定是存在的。我在想，跳出这个具体场景，如果回到Agent这个朴素的定义：它是可以“做事情”的，对吧？以前我们使用APP，本质上都是在消费内容或服务，我们并没有真的“创造”什么。Agent带来的增量，是否在于，它让每个人都能创造一些新东西？也就是说，人的创造力与创造欲望可以被释放出来。\n\n现在之所以大家不去创造，是因为“做工具”这件事本身门槛太高。我知道也有一些人说，我们人类就是懒，只想消费、不想创造。但我其实不太认同这个观点，我认为人类本质上还是有创造的欲望。比如说，当Agent能帮我实现一些功能时，即便我不会编程，我也可以用它写出一个小服务。但问题在于，这样的交互方式对不会编程的人来说仍然很困难。比如使用Cursor这样的平台，对于非程序员来说就是很痛苦的体验，因为它的底层逻辑还是建立在你理解一定程度编程逻辑的基础上。所以未来的交互方式应该更“产品化”，即当我想要实现一个功能或做一个小工具时，Agent所提供的服务完成度要更高，不只是给我一段代码，而是一个可直接使用的工具。如果只是给我代码，对于大多数用户来说门槛仍然很高。而对于IT从业者来说当然没问题。\n\n揭光发：这个问题其实是在说，现在越来越多的小白用户，能够通过Cursor这样的平台，通过AI IDE的方式，去实现他们想要的产品诉求。你是认为这是一个“增量市场”对吧？\n\n刘琼：是的。\n\n揭光发：对AI工具或者IDE本身来说，用户确实是新增的；但从专业从业者的角度来看，这其实是在抢原本属于他们的“存量市场”。\n\n刘琼：那会不会是因为他们本来的目标用户就不一样？\n\n揭光发：也可以这么理解。你刚才提到的用户，确实是在满足原本没有被很好覆盖的需求，是那些以往很难被满足，或者门槛相对较高的一些边缘需求。但从实际商业价值的角度讲，这些需求未必真的产生足够的经济价值。可能你几十万人做出一两个成型产品，然后投入市场运营，发现某个项目真的能成规模，那也是极小概率事件。这更多是一种自娱自乐的行为。对我来说，这就是我对这件事情的看法。\n\n但从另一个角度来看，小白用户现在确实可以通过AI，做出看起来像模像样的产品了。进一步延伸，一位小白经过几轮学习训练，可能就能做出一个可交付的、甚至能卖钱的产品。比如说，我帮你做一个企业网站或者一个简单的管理系统，过去你可能收费几万元，现在只要几百块钱就搞定了。这其实就是更“低端”层级的产品交付，它可能是一个新的方向。从业人员结合AI工具，可以用更低的价格抢占原本收费更高、价值更高的市场。从这个角度来看，AI在一定程度上是在抢夺存量、压缩存量，并将市场价值向下压缩。由此带来的，是对整个行业的冲击。以编程为例，我的观察是，如果你本身就是比较优秀、资深的开发者，在加入AI的辅助之后，你的发展路径会更深更广。但如果你本身是终端甚至偏低端的开发者，相较于小白用户，其实并无明显优势。这意味着行业尾部的一部分人群，会被AI折叠掉，而高端开发者则能借助AI继续增强自身的专业深度，实现效率提升。这是我观察到的两个极端。我认为，这种结构在编程行业如此，在其他行业亦然。这并不是说“专业”会失效，而是“低端专业”会被替代。只要你在一个领域里依然是高水平的人才，配合AI工具，你仍然能走得更远。未来社会对高端专业的需求将持续增加，而对低端专业的需求则会显著减少。因为这部分能力的可替代性太强，随时都可以找“阿猫阿狗”来做，甚至甲方自己也能轻松解决，这导致中低端岗位越来越“朴素化”，不再需要专职设置。这种结构的演变，会使得整个行业收缩为由少数资深专家带着AI完成大量任务的形态，原来那种完整的人才梯队结构将逐渐消失。很可能将来的极端局面是，所有人都是资深的专家，带着一堆AI在工作。\n\n但这里存在一个悖论：你要如何跨过那道坎，成长为资深？目前很多人误以为不需要学习了，其实这是最可怕的事。我在给年轻学生讲AI基础课时会特别强调，我们可以使用AI，但不要让AI替你写作业、写作文。写作业可以让AI帮你改，作文也可以让它给你反馈。但不能让AI代替你自己去成长。成长应当是你自己的责任。不要因为有AI就停止学习。如果哪天突然停电，或AI无法使用，你就什么都做不了，那才是真正的可怕。\n\n刘琼：确实很难做到。\n\n揭光发：对，是很难。\n\n刘琼：因为人很容易就会产生依赖。\n\n揭光发：一旦依赖成习惯，让AI替你做所有事，你自身的成长就会停滞，你不会进步了。\n\n刘琼：接下来的问题是：我们今天的讨论，其实都是建立在“基模能力”的基础上，来探讨Agent的发展。如果说大模型（即基模）的发展遇到瓶颈，或者出现了新的范式，那么我们今天所讨论的这些趋势会发生什么变化？各位专家怎么看？\n\n张俊九：从智能体自身范式的角度来看，我认为变化不会太大。因为它已经将一个人的基本能力进行了抽象。人类发挥到极致，无非就是比别人聪明一点、勤奋一点。而对于智能体而言，就是调用的基本能力更强、调用工具的种类更丰富、更精准。从这个底层逻辑来看，我认为Agent的范式不会有太大变化。当然，正如刘老师所说，基模能力确实是限制智能体发展的核心基础。没有大模型的演进，大家也不会重新提出Agent这个概念。毕竟Agent并不是一个新的概念。正是因为基模发展到了一定阶段，大家才开始重新相信，曾经的想象有可能实现，于是才有了近两年围绕Agent的热烈讨论、大量投入与时间精力的投入。因此，我依然认为基模是基础。当然，它是否能真正具备类似人类的认知能力，例如“这是一个杯子”，换一个样子后仍然识别为杯子——这种“迁移学习”能力，目前还没有任何一种算法能完全模拟出来。这需要对人脑进行深入研究。\n\n但如果只从方法论层面来看，无论是当前主流的各种底层算法，还是新提出的架构，技术上都有优劣。例如DeepSeek追求极致性价比，但其采用的MoE(专家混合,Mixture of Experts)架构可能会带来更高的幻觉率。这些都是技术上的取舍。但无论如何，“够用、好用、能用”才是实现落地的基本标准。在此基础上，我认为未来很可能会出现更多面向特定方向的专家模型，而不是依靠一个通用基模解决所有问题。我倾向于认为，社会分工这件事不会因为一个大模型而被取代。\n\n廉和：我并不认为存在“行业化的基模”，基模依旧是通用的。但在通用基模的基础上，确实需要加入行业数据，通过微调或Contextual Prompt等手段，才能完成行业化任务，形成行业化的Agent。也就是说，并不存在“行业化的基模”，但存在“行业化的Agent”。\n\n我可能与刚才另一位讲者的观点略有不同。关于“基模是否能学习人类的所有能力”，现在并没有确凿证据说明模型无法学习某项人类能力。我更倾向于这个观点。同时也有观点认为，AI的缩写其实不该是Artificial Intelligence，而应是Another Intelligence。换句话说，我们是否真的需要AI完全对标人脑？或许不需要。某些方面，AI已经超过人脑，不必非得模仿人脑所有功能。\n\n刘琼：好的，时间关系，我们的圆桌讨论也即将进入尾声。最后请三位嘉宾用一句话总结你们心目中“终极Agent”的价值。谁先来？\n\n张俊九：从To B的角度出发，我认为我们应致力于提供一种可控、高效、安全的Agent服务模式，这也是我们一直努力的方向。\n\n廉和：我觉得对我来说，Agent最重要的一点是它能“懂我”。它是可以围绕某一个人去构建的，我还是想回到这个出发点来讲。为什么我认为这件事如此重要？因为我们刚才也讨论过，AI作为一种another intelligence，未来的社会到底是由AI来主导和运转，还是我们希望未来是一个“人机协作”的社会？我是坚定的“拯救派”，所以我认为需要找到一条路径，让人类个体在未来社会中依然能够持续创造价值。我现在能想到的方式是：单靠一个人可能很难，但如果这个人拥有一个理解他、能够配合他的Agent，那还是有实现可能性的。这个Agent应该是为这个人量身打造的，而不是那种万能型、什么都能干的。我觉得这正是智能体带给我最大的希望，或者说是最大的潜在可能性。\n\n揭光发：我有一句话，从两年前就一直讲到现在，无论是作为一种预言还是一种愿景，其实我坚信——Agent一定是未来的主流生产力，无论是在数字世界还是在物理世界。关键是这个“事情”发生之后，人类接下来要做什么？我们会继续参与劳动，尝试从Agent所不能胜任的领域中寻找差异化价值？还是说我们要去开拓一些原本从未设想过的方向？这其实就是一种生产关系的变化。现在，随着Agent的出现，超级对齐（Superalignment）那位创始人也提出了这个问题。我们确实还没有真正开始去思考它——当AI释放了所有人的生产力之后，我们以怎样的心态去继续生存？到时候我们可能要重新寻找自身的价值，创造属于自己的东西。这种探索可以是向外的，比如探索太空，也可以是向内的，比如进入虚拟世界、创造虚拟人生，重新体验所有过程，这一切都有可能。但如果非要用一句话概括，我依然会说：Agent一定是未来的主流生产力。\n\n刘琼：那是不是意味着以后人人都会有一个，甚至多个Agent？\n\n揭光发：对，一定会的。\n\n刘琼：时间关系，我们今天的圆桌差不多就要结束了。其实刚刚我们和三位嘉宾讨论了智能体的多个方面，从概念定义、产品形态，到技术、生态与商业路径，甚至进一步讨论了它在社会层面可能带来的影响。智能体发展至今，技术演进远未停歇，也尚未进入一个稳定的状态。事实上，其发展速度可能比我们原先想象的还要快。因此也许在不久的将来，当我们再次谈论这个话题时，很多观点与判断都可能已经发生变化。\n\n不管怎样，今天关于智能体的这场讨论是非常充分的。感谢三位嘉宾的真挚分享，他们的讨论不仅深刻，而且开放，为我们带来了诸多有价值的思考。同时也感谢所有观众的参与。我们期待下次，能够在这个话题上继续碰撞出更多火花。![Image](https://mmbiz.qpic.cn/mmbiz_png/ljT2Dmxwr8zh6UlqGqxBZ2RK2WLZ48DVFRawyon4IfrLDwvNPwtwz9ygfPU8UnWuEDzsgoIUFqiaxNyoW2hgHYA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1)\n\n**推荐阅读**\n\n**仲夏六日谈：**[《异化与突围：AI一代的爱与忧愁｜4万字圆桌实录》](https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&mid=2650991864&idx=1&sn=0b61c90f42e6aca15dc57d67003c38af&scene=21#wechat_redirect)\n\n仲夏六日谈：[《信息蜂房，更好信息生态的可能｜3万字圆桌实录》](https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&mid=2650991875&idx=1&sn=dd69eb31070908107f5a83dff9327c11&scene=21#wechat_redirect)\n\n![Image](https://mmbiz.qpic.cn/mmbiz_jpg/ljT2Dmxwr8wrkNPIxXm9McZgEBZianN1a4BHibxC28FXiamGP8eTJJSSmnyE3ZmYia53KFicqPIyqsxLWw0yLr3Qoibg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1)\n\n**👇 点个“在看”****分享洞见**\n\n仲夏六日谈2025 · 目录\n\n上一篇信息蜂房，更好信息生态的可能｜3万字圆桌实录下一篇AI时代如何把想象力变成一种竞争优势？｜2万字圆桌实录\n\n继续滑动看下一个\n\n轻触阅读原文\n\n腾讯研究院\n\n向上滑动看下一个\n\n腾讯研究院\n\nComment"
  },
  {
    "path": "cases/link-with-imageless-alt.html",
    "title": "link with imageless alt",
    "expected": "[This is some text next to the image.](https://example.com)"
  },
  {
    "path": "cases/zero-height-container.html",
    "title": "zero height container",
    "expected": "This content is inside a zero-height container.\n\nIt should still be visible in the output."
  }
]